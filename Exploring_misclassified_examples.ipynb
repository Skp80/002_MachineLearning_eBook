{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploring misclassified examples",
      "provenance": [],
      "collapsed_sections": [
        "ySaiWxp3UhyQ",
        "ls5mBilqV3o3",
        "oeaA3yEUVuR_",
        "7g_mPPE2WxoI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skp80/002_MachineLearning_eBook/blob/master/Exploring_misclassified_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG46seRNCt8W",
        "colab_type": "text"
      },
      "source": [
        "Here's a quick working code example to give you a confusion matrix of misclassified examples in Weights & Biases.\n",
        "\n",
        "To see a live example in the UI, check out [this report →](https://app.wandb.ai/mathisfederico/wandb_features/reports/Examine-your-classification-model's-weaknesses--VmlldzoxMzE3NTU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySaiWxp3UhyQ",
        "colab_type": "text"
      },
      "source": [
        "# Install Wandb on colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmv94H-AwTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "0174ff6d-96fc-4999-a72d-086b5104a511"
      },
      "source": [
        "!pip install wandb -qq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 16.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 15.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25h  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHiaQAB9UZRa",
        "colab_type": "text"
      },
      "source": [
        "# Extand WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO1MSGLeAzWp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df67d92b-3975-465f-b6e3-0dd9f21c68de"
      },
      "source": [
        "#@title Double click to see the code\n",
        "import numpy as np\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "class WandbClassificationCallback(WandbCallback):\n",
        "\n",
        "    def __init__(self, monitor='val_loss', verbose=0, mode='auto',\n",
        "                 save_weights_only=False, log_weights=False, log_gradients=False,\n",
        "                 save_model=True, training_data=None, validation_data=None,\n",
        "                 labels=[], data_type=None, predictions=1, generator=None,\n",
        "                 input_type=None, output_type=None, log_evaluation=False,\n",
        "                 validation_steps=None, class_colors=None, log_batch_frequency=None,\n",
        "                 log_best_prefix=\"best_\", \n",
        "                 log_confusion_matrix=False,\n",
        "                 confusion_examples=0, confusion_classes=5):\n",
        "        \n",
        "        super().__init__(monitor=monitor,\n",
        "                        verbose=verbose, \n",
        "                        mode=mode,\n",
        "                        save_weights_only=save_weights_only,\n",
        "                        log_weights=log_weights,\n",
        "                        log_gradients=log_gradients,\n",
        "                        save_model=save_model,\n",
        "                        training_data=training_data,\n",
        "                        validation_data=validation_data,\n",
        "                        labels=labels,\n",
        "                        data_type=data_type,\n",
        "                        predictions=predictions,\n",
        "                        generator=generator,\n",
        "                        input_type=input_type,\n",
        "                        output_type=output_type,\n",
        "                        log_evaluation=log_evaluation,\n",
        "                        validation_steps=validation_steps,\n",
        "                        class_colors=class_colors,\n",
        "                        log_batch_frequency=log_batch_frequency,\n",
        "                        log_best_prefix=log_best_prefix)\n",
        "                        \n",
        "        self.log_confusion_matrix = log_confusion_matrix\n",
        "        self.confusion_examples = confusion_examples\n",
        "        self.confusion_classes = confusion_classes\n",
        "               \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if self.generator:\n",
        "            self.validation_data = next(self.generator)\n",
        "\n",
        "        if self.log_weights:\n",
        "            wandb.log(self._log_weights(), commit=False)\n",
        "\n",
        "        if self.log_gradients:\n",
        "            wandb.log(self._log_gradients(), commit=False)\n",
        "        \n",
        "        if self.log_confusion_matrix:\n",
        "            if self.validation_data is None:\n",
        "                wandb.termwarn(\n",
        "                    \"No validation_data set, pass a generator to the callback.\")\n",
        "            elif self.validation_data and len(self.validation_data) > 0:\n",
        "                wandb.log(self._log_confusion_matrix(), commit=False)                    \n",
        "\n",
        "        if self.input_type in (\"image\", \"images\", \"segmentation_mask\") or self.output_type in (\"image\", \"images\", \"segmentation_mask\"):\n",
        "            if self.validation_data is None:\n",
        "                wandb.termwarn(\n",
        "                    \"No validation_data set, pass a generator to the callback.\")\n",
        "            elif self.validation_data and len(self.validation_data) > 0:\n",
        "                if self.confusion_examples > 0:\n",
        "                    wandb.log({'confusion_examples': self._log_confusion_examples(\n",
        "                                                    confusion_classes=self.confusion_classes,\n",
        "                                                    max_confused_examples=self.confusion_examples)}, commit=False)\n",
        "                if self.predictions > 0:\n",
        "                    wandb.log({\"examples\": self._log_images(\n",
        "                        num_images=self.predictions)}, commit=False)\n",
        "\n",
        "        wandb.log({'epoch': epoch}, commit=False)\n",
        "        wandb.log(logs, commit=True)\n",
        "\n",
        "        self.current = logs.get(self.monitor)\n",
        "        if self.current and self.monitor_op(self.current, self.best):\n",
        "            if self.log_best_prefix:\n",
        "                wandb.run.summary[\"%s%s\" % (self.log_best_prefix, self.monitor)] = self.current\n",
        "                wandb.run.summary[\"%s%s\" % (self.log_best_prefix, \"epoch\")] = epoch\n",
        "                if self.verbose and not self.save_model:\n",
        "                    print('Epoch %05d: %s improved from %0.5f to %0.5f' % (\n",
        "                        epoch, self.monitor, self.best, self.current))\n",
        "            if self.save_model:\n",
        "                self._save_model(epoch)\n",
        "            self.best = self.current\n",
        "        \n",
        "    def _log_confusion_matrix(self):\n",
        "        x_val = self.validation_data[0]\n",
        "        y_val = self.validation_data[1]\n",
        "        y_val = np.argmax(y_val, axis=1)\n",
        "        y_pred = np.argmax(self.model.predict(x_val), axis=1)\n",
        "\n",
        "        confmatrix = confusion_matrix(y_pred, y_val, labels=range(len(self.labels)))\n",
        "        confdiag = np.eye(len(confmatrix)) * confmatrix\n",
        "        np.fill_diagonal(confmatrix, 0)\n",
        "\n",
        "        confmatrix = confmatrix.astype('float')\n",
        "        n_confused = np.sum(confmatrix)\n",
        "        confmatrix[confmatrix == 0] = np.nan\n",
        "        confmatrix = go.Heatmap({'coloraxis': 'coloraxis1', 'x': self.labels, 'y': self.labels, 'z': confmatrix,\n",
        "                                 'hoverongaps':False, 'hovertemplate': 'Predicted %{y}<br>Instead of %{x}<br>On %{z} examples<extra></extra>'})\n",
        "\n",
        "        confdiag = confdiag.astype('float')\n",
        "        n_right = np.sum(confdiag)\n",
        "        confdiag[confdiag == 0] = np.nan\n",
        "        confdiag = go.Heatmap({'coloraxis': 'coloraxis2', 'x': self.labels, 'y': self.labels, 'z': confdiag,\n",
        "                               'hoverongaps':False, 'hovertemplate': 'Predicted %{y} just right<br>On %{z} examples<extra></extra>'})\n",
        "\n",
        "        fig = go.Figure((confdiag, confmatrix))\n",
        "        transparent = 'rgba(0, 0, 0, 0)'\n",
        "        n_total = n_right + n_confused\n",
        "        fig.update_layout({'coloraxis1': {'colorscale': [[0, transparent], [0, 'rgba(180, 0, 0, 0.05)'], [1, f'rgba(180, 0, 0, {max(0.2, (n_confused/n_total) ** 0.5)})']], 'showscale': False}})\n",
        "        fig.update_layout({'coloraxis2': {'colorscale': [[0, transparent], [0, f'rgba(0, 180, 0, {min(0.8, (n_right/n_total) ** 2)})'], [1, 'rgba(0, 180, 0, 1)']], 'showscale': False}})\n",
        "\n",
        "        xaxis = {'title':{'text':'y_true'}, 'showticklabels':False}\n",
        "        yaxis = {'title':{'text':'y_pred'}, 'showticklabels':False}\n",
        "\n",
        "        fig.update_layout(title={'text':'Confusion matrix', 'x':0.5}, paper_bgcolor=transparent, plot_bgcolor=transparent, xaxis=xaxis, yaxis=yaxis)\n",
        "        \n",
        "        return {'confusion_matrix': wandb.data_types.Plotly(fig)}\n",
        "\n",
        "    def _log_confusion_examples(self, rescale=255, confusion_classes=5, max_confused_examples=3):\n",
        "            x_val = self.validation_data[0]\n",
        "            y_val = self.validation_data[1]\n",
        "            y_val = np.argmax(y_val, axis=1)\n",
        "            y_pred = np.argmax(self.model.predict(x_val), axis=1)\n",
        "\n",
        "            # Grayscale to rgb\n",
        "            if x_val.shape[-1] == 1:\n",
        "                x_val = np.concatenate((x_val, x_val, x_val), axis=-1)\n",
        "\n",
        "            confmatrix = confusion_matrix(y_pred, y_val, labels=range(len(self.labels)))\n",
        "            np.fill_diagonal(confmatrix, 0)\n",
        "\n",
        "            def example_image(class_index, x_val=x_val, y_pred=y_pred, y_val=y_val, labels=self.labels, rescale=rescale):\n",
        "                image = None\n",
        "                title_text = 'No example found'\n",
        "                color = 'red'\n",
        "\n",
        "                right_predicted_images = x_val[np.logical_and(y_pred==class_index, y_val==class_index)]\n",
        "                if len(right_predicted_images) > 0:\n",
        "                    image = rescale * right_predicted_images[0]\n",
        "                    title_text = 'Predicted right'\n",
        "                    color = 'rgb(46, 184, 46)'\n",
        "                else:\n",
        "                    ground_truth_images = x_val[y_val==class_index]\n",
        "                    if len(ground_truth_images) > 0:\n",
        "                        image = rescale * ground_truth_images[0]\n",
        "                        title_text = 'Example'\n",
        "                        color = 'rgb(255, 204, 0)'\n",
        "\n",
        "                return image, title_text, color\n",
        "\n",
        "            n_cols = max_confused_examples + 2\n",
        "            subplot_titles = [\"\"] * n_cols\n",
        "            subplot_titles[-2:] = [\"y_true\", \"y_pred\"]\n",
        "            subplot_titles[max_confused_examples//2] = \"confused_predictions\"\n",
        "            \n",
        "            n_rows = min(len(confmatrix[confmatrix > 0]), confusion_classes)\n",
        "            fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=subplot_titles)\n",
        "            for class_rank in range(1, n_rows+1):\n",
        "                indx = np.argmax(confmatrix)\n",
        "                indx = np.unravel_index(indx, shape=confmatrix.shape)\n",
        "                if confmatrix[indx] == 0:\n",
        "                    break\n",
        "                confmatrix[indx] = 0\n",
        "\n",
        "                class_pred, class_true = indx[0], indx[1]\n",
        "                mask = np.logical_and(y_pred==class_pred, y_val==class_true)\n",
        "                confused_images = x_val[mask]\n",
        "\n",
        "                # Confused images\n",
        "                n_images_confused = min(max_confused_examples, len(confused_images))\n",
        "                for j in range(n_images_confused):\n",
        "                    fig.add_trace(go.Image(z=rescale*confused_images[j],\n",
        "                                        name=f'Predicted: {self.labels[class_pred]} | Instead of: {self.labels[class_true]}',\n",
        "                                        hoverinfo='name', hoverlabel={'namelength' :-1}),\n",
        "                                row=class_rank, col=j+1)\n",
        "                    fig.update_xaxes(showline=True, linewidth=5, linecolor='red', row=class_rank, col=j+1, mirror=True)\n",
        "                    fig.update_yaxes(showline=True, linewidth=5, linecolor='red', row=class_rank, col=j+1, mirror=True)\n",
        "\n",
        "                # Comparaison images\n",
        "                for i, class_index in enumerate((class_true, class_pred)):\n",
        "                    col = n_images_confused+i+1\n",
        "                    image, title_text, color = example_image(class_index)\n",
        "                    fig.add_trace(go.Image(z=image, name=self.labels[class_index], hoverinfo='name', hoverlabel={'namelength' :-1}), row=class_rank, col=col)    \n",
        "                    fig.update_xaxes(showline=True, linewidth=5, linecolor=color, row=class_rank, col=col, mirror=True, title_text=title_text)\n",
        "                    fig.update_yaxes(showline=True, linewidth=5, linecolor=color, row=class_rank, col=col, mirror=True, title_text=self.labels[class_index])\n",
        "\n",
        "            fig.update_xaxes(showticklabels=False)\n",
        "            fig.update_yaxes(showticklabels=False)\n",
        "            \n",
        "            return wandb.data_types.Plotly(fig)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m import wandb.keras called before import keras or import tensorflow.keras.  This can lead to a version mismatch, W&B now assumes tensorflow.keras\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moCd2NhqU6Ll",
        "colab_type": "text"
      },
      "source": [
        "# Log the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls5mBilqV3o3",
        "colab_type": "text"
      },
      "source": [
        "## Build the Mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPQ-fQ-UHWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "num_classes = 10\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeaA3yEUVuR_",
        "colab_type": "text"
      },
      "source": [
        "## Setup parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P448OQhVtzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameter_defaults = dict(\n",
        "  dropout_1 = 0.25,\n",
        "  dropout_2 = 0.5,\n",
        "  learning_rate = 1.0,\n",
        "  epochs = 20,\n",
        "  batch_size = 128,\n",
        "  conv2d_1_filters = 32,\n",
        "  conv2d_1_kernel_size= 3,\n",
        "  conv2d_2_filters = 32,\n",
        "  conv2d_2_kernel_size = 3,\n",
        "  dense_1_units = 128,\n",
        "  pool_1_size = 2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g_mPPE2WxoI",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laPqBos-WyJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run = wandb.init(project=\"confusion-matrix\", config=hyperparameter_defaults)\n",
        "if run is None:\n",
        "    raise ValueError(\"Wandb didn't initialize properly\")\n",
        "config = wandb.config\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(config.conv2d_1_filters, kernel_size=(config.conv2d_1_kernel_size, config.conv2d_1_kernel_size),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(config.conv2d_2_filters, (config.conv2d_2_kernel_size, config.conv2d_2_kernel_size), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(config.pool_1_size, config.pool_1_size)))\n",
        "model.add(Dropout(config.dropout_1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(config.dense_1_units, activation='relu'))\n",
        "model.add(Dropout(config.dropout_2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(config.learning_rate),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIBth9jkXP2N",
        "colab_type": "text"
      },
      "source": [
        "## Fit the model\n",
        "\n",
        "Parameters:\n",
        "\n",
        "- log_confusion_matrix (bool) : If true, log the confusion matrix at each epochs.\n",
        "- confusion_classes (int) : the number of worst confusion classes to show.\n",
        "- confusion_examples (int) : the number of confusion examples to show for each confusion class. (0 is disabled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_zk7uiDXRsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=config.batch_size,\n",
        "          epochs=config.epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[\n",
        "              WandbClassificationCallback(input_type=\"image\", log_confusion_matrix=True,\n",
        "                                          confusion_examples=3, confusion_classes=5,\n",
        "                                          validation_data=(x_test, y_test), labels=list(range(10))),\n",
        "              ]\n",
        "          )\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}